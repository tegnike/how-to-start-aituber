<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>AITuberのつくりかた サンプルアプリ</title>

  <!-- settings.jsをモジュールとしてインポート -->
  <script type="module">
    import { DEFAULT_SETTINGS } from './settings.js';
    window.DEFAULT_SETTINGS = DEFAULT_SETTINGS;  // グローバルスコープで利用できるようにする
  </script>

  <style>
    body {
      font-family: sans-serif;
      margin: 20px;
      background-color: #f4f4f4;
    }
    #status, #error-message {
      padding: 10px;
      background: #fff;
      border: 1px solid #ddd;
      margin-bottom: 20px;
    }
    #error-message {
      display: none;
      background: #fff0f0;
      border-color: #ffcdd2;
      color: #d32f2f;
    }
    #error-details {
      display: none;
      margin-top: 10px;
      padding: 10px;
      background: #fff;
      border: 1px solid #ddd;
      font-family: monospace;
      white-space: pre-wrap;
    }
    .error #error-details {
      display: block;
    }
    .settings {
      background: #fff;
      padding: 20px;
      border: 1px solid #ddd;
      margin-bottom: 20px;
    }
    .settings h3 {
      margin: 15px 0 5px;
      padding-bottom: 5px;
      border-bottom: 1px solid #eee;
    }
    .settings textarea {
      width: 100%;
      min-height: 100px;
      padding: 5px;
      margin: 5px 0;
      font-family: sans-serif;
    }
    .settings-group {
      margin-bottom: 20px;
    }
    .controls {
      margin: 20px 0;
    }
    .controls button {
      padding: 10px 20px;
      margin-right: 10px;
      cursor: pointer;
    }
    button:disabled {
      cursor: not-allowed;
      opacity: 0.6;
    }
    #conversation-history {
      background: #fff;
      padding: 20px;
      border: 1px solid #ddd;
      margin-top: 20px;
      max-height: 300px;
      overflow-y: auto;
    }
    
    .conversation-item {
      margin-bottom: 15px;
      padding-bottom: 15px;
      border-bottom: 1px solid #eee;
    }
    
    .user-message {
      color: #2196F3;
      margin-bottom: 5px;
    }
    
    .assistant-response {
      color: #4CAF50;
    }
    
    .settings-header {
      display: flex;
      align-items: center;
      cursor: pointer;
      user-select: none;
    }
    
    .settings-header h2 {
      margin: 0;
    }
    
    .settings-toggle {
      margin-left: auto;
      padding: 5px;
      font-size: 20px;
      transition: transform 0.3s;
    }
    
    .settings-content {
      transition: max-height 0.3s ease-out;
      overflow: hidden;
      max-height: 2000px; /* 十分大きな値 */
    }
    
    .settings-content.collapsed {
      max-height: 0;
    }
    
    /* 矢印の回転 */
    .settings-toggle.collapsed {
      transform: rotate(-90deg);
    }
  </style>
</head>
<body>
  <h1>AITuberのつくりかた サンプルアプリ</h1>
  
  <div class="settings">
    <div class="settings-header" onclick="toggleSettings()">
      <h2>設定</h2>
      <span class="settings-toggle">▼</span>
    </div>
    <div class="settings-content">
      <div class="settings-group">
        <h3>YouTube設定</h3>
        <div class="setting-item">
          <label for="youtubeApiKey">API Key:</label>
          <input type="text" id="youtubeApiKey">
        </div>
        <div class="setting-item">
          <label for="videoId">配信ID:</label>
          <input type="text" id="videoId">
        </div>
        <div class="setting-item">
          <label for="waitTime">チャット取得間隔（秒）:</label>
          <input type="number" id="waitTime" min="1">
        </div>
      </div>

      <div class="settings-group">
        <h3>OpenAI設定</h3>
        <div class="setting-item">
          <label for="openaiApiKey">API Key:</label>
          <input type="text" id="openaiApiKey">
        </div>
        <div class="setting-item">
          <label for="openaiModel">モデル:</label>
          <select id="openaiModel">
            <option value="gpt-4o-mini">gpt-4o-mini</option>
            <option value="gpt-4o">gpt-4o</option>
          </select>
        </div>
        <div class="setting-item">
          <label for="systemPrompt">システムプロンプト:</label>
          <textarea id="systemPrompt"></textarea>
        </div>
        <div class="setting-item">
          <label for="commentSelectionPrompt">コメント選択プロンプト:</label>
          <textarea id="commentSelectionPrompt"></textarea>
        </div>
      </div>

      <div class="settings-group">
        <h3>VOICEVOX設定</h3>
        <label>
          エンドポイント:
          <input type="text" id="voicevoxEndpoint">
        </label>
        <label>
          話者:
          <select id="voicevoxSpeaker">
            <option value="2">四国めたん/普通</option>
            <option value="0">四国めたん/あまあま</option>
            <option value="6">四国めたん/ツンツン</option>
            <option value="4">四国めたん/セクシー</option>
            <option value="36">四国めたん/ささやき</option>
            <option value="37">四国めたん/ヒソヒソ</option>
            <option value="3">ずんだもん/普通</option>
            <option value="1">ずんだもん/あまあま</option>
            <option value="7">ずんだもん/ツンツン</option>
            <option value="5">ずんだもん/セクシー</option>
            <option value="22">ずんだもん/ささやき</option>
            <option value="38">ずんだもん/ヒソヒソ</option>
            <option value="8">春日部つむ</option>
            <option value="10">雨晴はう</option>
            <option value="9">波音リツ</option>
            <option value="11">玄野武宏/普通</option>
            <option value="41">玄野武宏/悲しみ</option>
            <option value="12">白上虎太郎/ふつう</option>
            <option value="32">白上虎太郎/わーい</option>
            <option value="33">白上虎太郎/びくびく</option>
            <option value="34">白上虎太郎/おこ</option>
            <option value="35">白上虎太郎/びえーん</option>
            <option value="13">青山龍星</option>
            <option value="14">冥鳴ひまり</option>
            <option value="16">九州そら/普通</option>
            <option value="15">九州そら/あまあま</option>
            <option value="18">九州そら/ツンツン</option>
            <option value="17">九州そら/セクシー</option>
            <option value="19">九州そら/ささやき</option>
            <option value="20">もち子さん</option>
            <option value="21">剣崎雌雄</option>
            <option value="23">WhiteCUL/普通</option>
            <option value="24">WhiteCUL/たのしい</option>
            <option value="25">WhiteCUL/かなしい</option>
            <option value="26">WhiteCUL/びえーん</option>
            <option value="27">後鬼/人間ver.</option>
            <option value="28">後鬼/ぬいぐるみver.</option>
            <option value="29">No.7/普通</option>
            <option value="30">No.7/アナウンス</option>
            <option value="31">No.7/読み聞かせ</option>
            <option value="42">ちび式じい</option>
            <option value="43">櫻歌ミコ/普通</option>
            <option value="44">櫻歌ミコ/第二形態</option>
            <option value="45">櫻歌ミコ/ロリ</option>
            <option value="46">小夜/SAYO</option>
            <option value="47">ナースロボ＿タイプＴ/普通</option>
            <option value="48">ナースロボ＿タイプＴ/楽々</option>
            <option value="49">ナースロボ＿タイプＴ/恐怖</option>
            <option value="50">ナースロボ＿タイプＴ/内緒話</option>
            <option value="51">†聖騎士 紅桜†</option>
            <option value="52">雀松朱司</option>
            <option value="53">麒ヶ島宗麟</option>
            <option value="54">春歌ナナ</option>
            <option value="55">猫使アル/普通</option>
            <option value="56">猫使アル/おちつき</option>
            <option value="57">猫使アル/うきうき</option>
            <option value="58">猫使ビィ/普通</option>
            <option value="59">猫使ビィ/おちつき</option>
            <option value="60">猫使ビィ/人見知り</option>
          </select>
        </label>
      </div>

      <div class="settings-group">
        <h3>VTubeStudio設定</h3>
        <div class="setting-item">
          <label for="vtsPort">ポート番号:</label>
          <input type="number" id="vtsPort" min="1" max="65535">
        </div>
      </div>

      <div class="settings-group">
        <h3>会話履歴設定</h3>
        <div class="setting-item">
          <label for="conversationHistorySize">保持する会話数:</label>
          <input type="number" id="conversationHistorySize" min="0" max="100">
          <small>（0は会話履歴を使用しない、最大100）</small>
        </div>
      </div>
    </div>
  </div>

  <div class="controls">
    <button id="startButton">開始</button>
    <button id="stopButton" disabled>停止</button>
  </div>

  <div id="status">待機中...</div>
  <div id="error-message"></div>
  <div id="error-details"></div>

  <div id="conversation-history">
    <div class="settings-header">
      <h2>会話履歴 (<span id="conversation-count">0</span>/<span id="conversation-max">0</span>件)</h2>
    </div>
    <div id="conversation-container"></div>
  </div>

  <script>
    // グローバル変数の初期化を最初に行う
    const statusDiv = document.getElementById('status');
    let isProcessing = false;
    let shouldContinue = false;
    let processedMessageIds = new Map();
    let conversationHistory = [];

    // VTubeStudio WebSocket接続の管理
    let vtsWebSocket = null;
    let vtsAuthenticated = false;
    const VTS_WEBSOCKET_URL = 'ws://localhost:';

    // 初期値を設定
    function initializeSettings() {
      document.getElementById('youtubeApiKey').value = DEFAULT_SETTINGS.YOUTUBE_API_KEY;
      document.getElementById('videoId').value = DEFAULT_SETTINGS.VIDEO_ID;
      document.getElementById('waitTime').value = DEFAULT_SETTINGS.WAIT_TIME;
      document.getElementById('openaiApiKey').value = DEFAULT_SETTINGS.OPENAI_API_KEY;
      document.getElementById('openaiModel').value = DEFAULT_SETTINGS.OPENAI_MODEL;
      document.getElementById('systemPrompt').value = DEFAULT_SETTINGS.SYSTEM_PROMPT;
      document.getElementById('commentSelectionPrompt').value = DEFAULT_SETTINGS.COMMENT_SELECTION_PROMPT;
      document.getElementById('voicevoxEndpoint').value = DEFAULT_SETTINGS.VOICEVOX_ENDPOINT;
      document.getElementById('voicevoxSpeaker').value = DEFAULT_SETTINGS.VOICEVOX_SPEAKER;
      document.getElementById('conversationHistorySize').value = DEFAULT_SETTINGS.CONVERSATION_HISTORY_SIZE;
      document.getElementById('vtsPort').value = DEFAULT_SETTINGS.VTS_PORT || '8001';
    }

    // DOMContentLoadedイベントで初期化を行う
    document.addEventListener('DOMContentLoaded', () => {
      initializeSettings();
      updateConversationDisplay();
      
      // VTubeStudioに接続
      connectToVTS();
      
      // イベントリスナーの設定
      document.getElementById('startButton').addEventListener('click', () => {
        if (isProcessing) return;
        
        // 設定値の検証
        const settings = getSettings();
        if (!settings.YOUTUBE_API_KEY) {
          showError("YouTube API Keyが設定されていません");
          return;
        }
        if (!settings.VIDEO_ID) {
          showError("配信IDが設定されていません");
          return;
        }
        if (!settings.OPENAI_API_KEY) {
          showError("OpenAI API Keyが設定されていません");
          return;
        }
        
        clearError();
        shouldContinue = true;
        isProcessing = true;
        processedMessageIds.clear();
        updateButtonState(true);
        console.log("処理を開始します"); // デバッグログ追加
        processNextComment();
      });

      document.getElementById('stopButton').addEventListener('click', () => {
        shouldContinue = false;
        isProcessing = false;
        updateButtonState(false);
        statusDiv.innerText = "停止しました";
        conversationHistory = [];
        updateConversationDisplay();
      });
    });

    // 設定値を取得する関数を修正
    function getSettings() {
      return {
        YOUTUBE_API_KEY: document.getElementById('youtubeApiKey').value,
        VIDEO_ID: document.getElementById('videoId').value,
        OPENAI_API_KEY: document.getElementById('openaiApiKey').value,
        OPENAI_MODEL: document.getElementById('openaiModel').value,
        VOICEVOX_ENDPOINT: document.getElementById('voicevoxEndpoint').value,
        VOICEVOX_SPEAKER: parseInt(document.getElementById('voicevoxSpeaker').value),
        WAIT_TIME: parseInt(document.getElementById('waitTime').value),
        SYSTEM_PROMPT: document.getElementById('systemPrompt').value,
        COMMENT_SELECTION_PROMPT: document.getElementById('commentSelectionPrompt').value,
        MESSAGE_LIFETIME: DEFAULT_SETTINGS.MESSAGE_LIFETIME,
        CONVERSATION_HISTORY_SIZE: parseInt(document.getElementById('conversationHistorySize').value),
        VTS_PORT: document.getElementById('vtsPort').value
      };
    }

    // ボタンの状態を更新する関数
    function updateButtonState(isRunning) {
      document.getElementById('startButton').disabled = isRunning;
      document.getElementById('stopButton').disabled = !isRunning;
    }

    // エラー表示用の関数を修正
    function showError(message, details = '') {
      const errorMessageDiv = document.getElementById('error-message');
      const errorDetailsDiv = document.getElementById('error-details');
      
      errorMessageDiv.style.display = 'block';
      errorMessageDiv.textContent = message;
      
      if (details) {
        errorDetailsDiv.style.display = 'block';
        errorDetailsDiv.textContent = details;
      } else {
        errorDetailsDiv.style.display = 'none';
      }
    }

    // エラー表示をクリアする関数を修正
    function clearError() {
      const errorMessageDiv = document.getElementById('error-message');
      const errorDetailsDiv = document.getElementById('error-details');
      
      errorMessageDiv.style.display = 'none';
      errorDetailsDiv.style.display = 'none';
    }

    // 期限切れのメッセージIDを削除する関数
    function cleanupProcessedMessages() {
      const settings = getSettings();
      const now = Date.now();
      const expiryTime = settings.MESSAGE_LIFETIME * 1000; // 秒をミリ秒に変換
      
      for (const [id, timestamp] of processedMessageIds) {
        if (now - timestamp > expiryTime) {
          processedMessageIds.delete(id);
        }
      }
    }

    // Youtubeからライブチャットを取得する関数
    async function fetchYoutubeLiveChat() {
      const settings = getSettings();
      statusDiv.innerText = "YouTubeライブチャットを取得中...";
      clearError();
      
      console.log("YouTube API呼び出し開始"); // デバッグログ追加
      
      try {
        // まずライブチャットIDを取得
        const videoUrl = `https://www.googleapis.com/youtube/v3/videos?part=liveStreamingDetails&id=${settings.VIDEO_ID}&key=${settings.YOUTUBE_API_KEY}`;
        console.log("動画情報取得URL:", videoUrl); // デバッグログ追加
        
        const videoResponse = await fetch(videoUrl);
        
        if (!videoResponse.ok) {
          const errorText = await videoResponse.text();
          console.error("YouTube API エラー:", errorText); // デバッグログ追加
          let errorMessage = `YouTube API エラー (${videoResponse.status})`;
          if (videoResponse.status === 403) {
            errorMessage = 'YouTube API キーが無効か、アクセス権限がありません';
          } else if (videoResponse.status === 404) {
            errorMessage = '指定された動画が見つかりません';
          }
          showError(errorMessage, errorText);
          return [];
        }

        const videoData = await videoResponse.json();
        console.log("取得した動画データ:", videoData); // デバッグログ追加
        
        if (!videoData.items?.[0]?.liveStreamingDetails?.activeLiveChatId) {
          showError('この動画はライブ配信ではないか、ライブチャットが無効になっています');
          return [];
        }

        const liveChatId = videoData.items[0].liveStreamingDetails.activeLiveChatId;
        
        // ライブチャットメッセージを取得
        const chatUrl = `https://www.googleapis.com/youtube/v3/liveChat/messages?part=snippet&liveChatId=${liveChatId}&key=${settings.YOUTUBE_API_KEY}`;
        const chatResponse = await fetch(chatUrl);
        
        if (!chatResponse.ok) {
          const errorText = await chatResponse.text();
          showError(
            'ライブチャットの取得に失敗しました',
            errorText
          );
          return [];
        }

        const chatData = await chatResponse.json();
        return chatData.items || [];

      } catch (error) {
        showError(
          'YouTube APIの呼び出しに失敗しました。',
          error.toString()
        );
        return [];
      }
    }

    // OpenAIを使って最適なコメントを選択する関数を追加
    async function selectBestComment(messages) {
      const settings = getSettings();
      
      const messagesList = messages.map(msg => ({
        id: msg.id,
        message: msg.snippet.displayMessage
      }));

      try {
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${settings.OPENAI_API_KEY}`
          },
          body: JSON.stringify({
            model: settings.OPENAI_MODEL,
            messages: [
              {"role": "system", "content": settings.COMMENT_SELECTION_PROMPT},
              {"role": "user", "content": "コメントリスト：" + JSON.stringify(messagesList, null, 2)}
            ]
          })
        });

        if (!response.ok) {
          console.error('コメント選択でエラーが発生しました。ランダム選択を使用します。');
          return null;
        }

        const data = await response.json();
        const result = JSON.parse(data.choices[0].message.content);
        return result.selectedId;

      } catch (error) {
        console.error('コメント選択でエラーが発生しました。ランダム選択を使用します。', error);
        return null;
      }
    }

    // 取得したチャットメッセージから最適なものを選ぶ関数を修正
    async function pickRandomChat(messages) {
      if (!messages || messages.length === 0) return null;
      
      // 期限切れのメッセージを削除
      cleanupProcessedMessages();
      
      // 未処理のメッセージをフィルタリング
      const unprocessedMessages = messages.filter(msg => !processedMessageIds.has(msg.id));
      
      if (unprocessedMessages.length === 0) return null;

      // すべてのメッセージを処理済みとしてマーク
      messages.forEach(msg => {
        processedMessageIds.set(msg.id, Date.now());
      });

      // OpenAIを使って最適なコメントを選択
      const selectedId = await selectBestComment(unprocessedMessages);
      let selectedMessage;

      if (selectedId) {
        selectedMessage = unprocessedMessages.find(msg => msg.id === selectedId);
      }

      // OpenAIでの選択に失敗した場合はランダムに選択
      if (!selectedMessage) {
        const randomIndex = Math.floor(Math.random() * unprocessedMessages.length);
        selectedMessage = unprocessedMessages[randomIndex];
      }
      
      return selectedMessage.snippet.displayMessage;
    }

    // OpenAI APIを呼び出す関数を修正
    async function getOpenAIResponse(commentText) {
      const settings = getSettings();
      statusDiv.innerText = "OpenAIに問い合わせ中...";
      clearError();
      
      // システムメッセージを含む基本的なメッセージ配列を作成
      const messages = [
        {"role": "system", "content": settings.SYSTEM_PROMPT}
      ];
      
      // 会話履歴がある場合は追加
      if (settings.CONVERSATION_HISTORY_SIZE > 0) {
        conversationHistory.forEach(entry => {
          messages.push(
            {"role": "user", "content": entry.userMessage},
            {"role": "assistant", "content": entry.assistantResponse}
          );
        });
      }
      
      // 現在のメッセージを追加
      messages.push({"role": "user", "content": commentText});

      const url = 'https://api.openai.com/v1/chat/completions';
      const payload = {
        model: settings.OPENAI_MODEL,
        messages: messages
      };

      try {
        const response = await fetch(url, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${settings.OPENAI_API_KEY}`
          },
          body: JSON.stringify(payload)
        });
        
        if (!response.ok) {
          const errorText = await response.text();
          let errorMessage = `OpenAI API エラー (${response.status})`;
          if (response.status === 401) {
            errorMessage = 'OpenAI API キーが無効です';
          } else if (response.status === 429) {
            errorMessage = 'OpenAI APIの利用制限に達しました';
          }
          showError(errorMessage, errorText);
          return "申し訳ありませんが、エラーが発生しました。";
        }

        const data = await response.json();
        if (data.error) {
          showError(
            'OpenAI APIでエラーが発生しました。',
            JSON.stringify(data.error, null, 2)
          );
          return "申し訳ありませんが、エラーが発生しました。";
        }
        if (data.choices && data.choices.length > 0) {
          const assistantResponse = data.choices[0].message.content.trim();
          
          // 会話履歴を更新
          if (settings.CONVERSATION_HISTORY_SIZE > 0) {
            conversationHistory.push({
              userMessage: commentText,
              assistantResponse: assistantResponse
            });
            
            // 履歴サイズを制限
            while (conversationHistory.length > settings.CONVERSATION_HISTORY_SIZE) {
              conversationHistory.shift();
            }
            
            // 会話履歴の表示を更新
            updateConversationDisplay();
          }
          
          return assistantResponse;
        }
        showError('OpenAI APIからの応答が不正です。');
        return "申し訳ありませんが、返答を生成できませんでした。";
      } catch (error) {
        showError(
          'OpenAI APIの呼び出しに失敗しました。',
          error.toString()
        );
        return "申し訳ありませんが、エラーが発生しました。";
      }
    }

    // 全体のフローを管理する関数を修正
    async function processNextComment() {
      if (!shouldContinue) return;
      
      try {
        const settings = getSettings();
        const messages = await fetchYoutubeLiveChat();
        const messageText = await pickRandomChat(messages);
        
        if (!messageText) {
          statusDiv.innerText = "チャットメッセージがありません。" + settings.WAIT_TIME + "秒後に再取得します。";
          if (shouldContinue) {
            setTimeout(processNextComment, settings.WAIT_TIME * 1000);
          }
          return;
        }

        console.log("取得したチャット:", messageText);
        const openaiResponse = await getOpenAIResponse(messageText);
        console.log("OpenAIからの返答:", openaiResponse);

        // speakWithVoicevoxの代わりにgenerateVoiceAndLipSyncを使用
        await generateVoiceAndLipSync(openaiResponse);
        
        // 音声発話完了後、直ちに次のコメントを探す
        if (shouldContinue) {
          statusDiv.innerText = "次のコメントを探しています...";
          processNextComment();
        }
      } catch (error) {
        console.error("処理中にエラーが発生:", error);
        showError("処理中にエラーが発生しました", error.toString());
        
        // エラーが発生しても継続する場合は、一定時間後に再試行
        if (shouldContinue) {
          const settings = getSettings();
          setTimeout(processNextComment, settings.WAIT_TIME * 1000);
        }
      }
    }

    function updateConversationDisplay() {
      const container = document.getElementById('conversation-container');
      const countElement = document.getElementById('conversation-count');
      const maxElement = document.getElementById('conversation-max');
      const settings = getSettings();
      
      // 件数表示を更新
      countElement.textContent = conversationHistory.length;
      maxElement.textContent = settings.CONVERSATION_HISTORY_SIZE;
      
      container.innerHTML = '';
      
      conversationHistory.forEach((entry, index) => {
        const item = document.createElement('div');
        item.className = 'conversation-item';
        
        const userMessage = document.createElement('div');
        userMessage.className = 'user-message';
        userMessage.textContent = `視聴者: ${entry.userMessage}`;
        
        const assistantResponse = document.createElement('div');
        assistantResponse.className = 'assistant-response';
        assistantResponse.textContent = `AI: ${entry.assistantResponse}`;
        
        item.appendChild(userMessage);
        item.appendChild(assistantResponse);
        container.appendChild(item);
      });
    }

    function toggleSettings() {
      const content = document.querySelector('.settings-content');
      const toggle = document.querySelector('.settings-toggle');
      
      content.classList.toggle('collapsed');
      toggle.classList.toggle('collapsed');
    }

    // VTubeStudioへの接続を確立
    async function connectToVTS() {
      const port = document.getElementById('vtsPort').value || '8001';
      const ws = new WebSocket(`ws://localhost:${port}`);
      
      ws.onopen = () => {
        console.log('VTubeStudio WebSocketに接続しました');
        // 認証プロセスを開始
        authenticateWithVTS();
      };
      
      ws.onclose = () => {
        console.log('VTubeStudio WebSocket接続が切断されました');
        vtsAuthenticated = false;
      };
      
      ws.onerror = (error) => {
        console.error('VTubeStudio WebSocketエラー:', error);
        showError('VTubeStudioとの接続に失敗しました');
      };
      
      ws.onmessage = handleVTSMessage;
    }

    // VTSからのメッセージを処理
    async function handleVTSMessage(event) {
      try {
        const response = JSON.parse(event.data);
        console.log('VTS Response:', response);
        
        if (response.messageType === 'APIError') {
          console.error('VTS APIエラー:', {
            message: response.data?.message,
            code: response.data?.errorID,
            details: response.data
          });
          return;
        }
        
        if (response.messageType === 'AuthenticationTokenResponse') {
          const token = response.data.authenticationToken;
          localStorage.setItem('vtsAuthToken', token);
          sendVTSAuthRequest(token);
        }
        else if (response.messageType === 'AuthenticationResponse') {
          vtsAuthenticated = response.data.authenticated;
          if (vtsAuthenticated) {
            console.log('VTubeStudioの認証に成功しました');
            setTimeout(requestModelList, 1000);
          }
        }
        else if (response.messageType === 'AvailableModelsResponse') {
          console.log('利用可能なモデル:', response.data.availableModels);
          
          const currentModel = response.data.availableModels.find(model => model.modelLoaded);
          if (currentModel) {
            console.log('現在ロードされているモデル:', currentModel);
            const request = {
              apiName: "VTubeStudioPublicAPI",
              apiVersion: "1.0",
              requestID: "parameter-list",
              messageType: "InputParameterListRequest",
              data: {
                modelID: currentModel.modelID
              }
            };
            vtsWebSocket.send(JSON.stringify(request));
          }
        }
        else if (response.messageType === 'InputParameterListResponse') {
          console.log('パラメータリストのレスポンス:', response);
          console.log('パラメータリスト:', response.data);
          console.log('パラメータリスト:', response.data.defaultParameters);
          
          if (response.data && response.data.defaultParameters) {
            const parameters = response.data.defaultParameters;
            console.log('すべてのパラメータ名:', parameters.map(p => p.name));
            
            // 口の開きに関連するパラメータを取得
            const mouthParams = parameters
              .filter(param => {
                const name = param.name.toLowerCase();
                
                // 目に関連するパラメータを除外
                if (name.includes('eye') || name.includes('目')) {
                  return false;
                }

                // より厳密な口パラメータの検索条件
                const mouthPatterns = [
                  'mouth_open',      // 一般的な口開きパラメータ
                  'mouth.open',      // ドット区切り
                  'mouth_openness',  // 開度パラメータ
                  'parammouth',      // VTSの標準的な命名
                  'mouthopen',       // キャメルケース
                  '口開き',          // 日本語
                  '口の開き',        // 日本語バリエーション
                  'あ口',           // 母音Aの口形
                  'mouth_a',        // 母音A（英語）
                ];

                return mouthPatterns.some(pattern => name.includes(pattern));
              })
              .map(param => param.name);
            
            // パラメータが見つからない場合は警告を表示
            if (mouthParams.length === 0) {
              console.warn('口の開閉に関連するパラメータが見つかりませんでした。以下の全パラメータ名を確認してください:');
              console.warn(parameters.map(p => p.name));
            } else {
              console.log('使用する口パラメータ:', mouthParams);
            }
            
            window.vtsParameters = parameters;
          } else {
            console.warn('パラメータが見つかりません:', response);
          }
        }
      } catch (error) {
        console.error('VTSメッセージ処理エラー:', error);
      }
    }

    // モデル一覧を取得
    function requestModelList() {
      const request = {
        apiName: "VTubeStudioPublicAPI",
        apiVersion: "1.0",
        requestID: "model-list",
        messageType: "AvailableModelsRequest"
      };
      vtsWebSocket.send(JSON.stringify(request));
    }

    // VTSに認証トークンをリクエスト
    function authenticateWithVTS() {
      const savedToken = localStorage.getItem('vtsAuthToken');
      
      if (savedToken) {
        sendVTSAuthRequest(savedToken);
      } else {
        const tokenRequest = {
          apiName: "VTubeStudioPublicAPI",
          apiVersion: "1.0",
          requestID: "token-request",
          messageType: "AuthenticationTokenRequest",
          data: {
            pluginName: "AITuber Sample App",
            pluginDeveloper: "Developer"
          }
        };
        vtsWebSocket.send(JSON.stringify(tokenRequest));
      }
    }

    // 保存されたトークンで認証
    function sendVTSAuthRequest(token) {
      const authRequest = {
        apiName: "VTubeStudioPublicAPI",
        apiVersion: "1.0",
        requestID: "auth-request",
        messageType: "AuthenticationRequest",
        data: {
          pluginName: "AITuber Sample App",
          pluginDeveloper: "Developer",
          authenticationToken: token
        }
      };
      vtsWebSocket.send(JSON.stringify(authRequest));
    }

    // 音声生成とリップシンク制御を行う関数
    async function generateVoiceAndLipSync(text) {
      try {
        const settings = getSettings();
        console.log('音声生成開始:', text);
        
        // タイムアウト設定を追加
        const timeout = 10000; // 10秒
        
        // audio_queryリクエストにタイムアウトを設定
        const queryPromise = fetch(`${settings.VOICEVOX_ENDPOINT}/audio_query?text=${encodeURIComponent(text)}&speaker=${settings.VOICEVOX_SPEAKER}`, {
          method: 'POST',
          signal: AbortSignal.timeout(timeout)
        });
        
        console.log('audio_query リクエスト開始');
        const query = await queryPromise;
        if (!query.ok) {
          throw new Error(`audio_query failed: ${query.status} ${query.statusText}`);
        }
        const queryJson = await query.json();
        console.log('audio_query 完了');
        
        // synthesis リクエストにタイムアウトを設定
        const synthesisPromise = fetch(`${settings.VOICEVOX_ENDPOINT}/synthesis?speaker=${settings.VOICEVOX_SPEAKER}`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(queryJson),
          signal: AbortSignal.timeout(timeout)
        });
        
        console.log('synthesis リクエスト開始');
        const synthesis = await synthesisPromise;
        if (!synthesis.ok) {
          throw new Error(`synthesis failed: ${synthesis.status} ${synthesis.statusText}`);
        }
        
        // 音声データを取得
        const audioData = await synthesis.arrayBuffer();
        console.log('音声データ取得完了:', audioData.byteLength, 'bytes');
        
        // 音声再生の準備
        const audioBlob = new Blob([audioData], { type: 'audio/wav' });
        const audioUrl = URL.createObjectURL(audioBlob);
        const audio = new Audio(audioUrl);
        
        // 音声再生とリップシンク制御を同期
        return new Promise((resolve, reject) => {
          let lipSyncStarted = false;
          
          audio.onplay = () => {
            console.log('音声再生開始');
            if (!lipSyncStarted) {
              lipSyncStarted = true;
              // リップシンク制御を開始
              controlLipSync(audioData).catch(error => {
                console.error('リップシンク制御エラー:', error);
              });
            }
          };
          
          audio.onended = () => {
            console.log('音声再生完了');
            URL.revokeObjectURL(audioUrl);
            resolve();
          };
          
          audio.onerror = (error) => {
            console.error('音声再生エラー:', error);
            URL.revokeObjectURL(audioUrl);
            reject(error);
          };
          
          // 音声再生開始
          audio.play().catch(error => {
            console.error('音声再生開始エラー:', error);
            reject(error);
          });
        });
        
      } catch (error) {
        if (error.name === 'TimeoutError') {
          console.error('VOICEVOXリクエストがタイムアウトしました:', error);
          showError('音声生成がタイムアウトしました。VOICEVOXサーバーの状態を確認してください。');
        } else {
          console.error('音声生成エラー:', error);
          showError('音声の生成に失敗しました: ' + error.message);
        }
        throw error;
      }
    }

    // リップシンク制御の関数を修正
    async function controlLipSync(audioData) {
      if (!vtsAuthenticated || !vtsWebSocket) {
        throw new Error('VTubeStudioが接続されていません');
      }

      if (!window.vtsParameters) {
        throw new Error('モデルパラメータが取得できていません');
      }

      console.log('リップシンク制御開始');
      
      const audioContext = new AudioContext();
      const audioBuffer = await audioContext.decodeAudioData(audioData);
      const channelData = audioBuffer.getChannelData(0);
      
      const interval = 100; // 100ms間隔で更新
      const samplesPerInterval = Math.floor(audioBuffer.sampleRate * (interval / 1000));
      
      // 口の開きに関連するパラメータを取得
      const mouthParams = window.vtsParameters
        .filter(param => {
          const name = param.name.toLowerCase();
          
          // 目に関連するパラメータを除外
          if (name.includes('eye') || name.includes('目')) {
            return false;
          }

          // より厳密な口パラメータの検索条件
          const mouthPatterns = [
            'mouth_open',      // 一般的な口開きパラメータ
            'mouth.open',      // ドット区切り
            'mouth_openness',  // 開度パラメータ
            'parammouth',      // VTSの標準的な命名
            'mouthopen',       // キャメルケース
            '口開き',          // 日本語
            '口の開き',        // 日本語バリエーション
            'あ口',           // 母音Aの口形
            'mouth_a',        // 母音A（英語）
          ];

          return mouthPatterns.some(pattern => name.includes(pattern));
        })
        .map(param => param.name);
      
      // パラメータが見つからない場合は警告を表示
      if (mouthParams.length === 0) {
        console.warn('口の開閉に関連するパラメータが見つかりませんでした。以下の全パラメータ名を確認してください:');
        console.warn(window.vtsParameters.map(p => p.name));
      } else {
        console.log('使用する口パラメータ:', mouthParams);
      }
      
      // レスポンスハンドラを設定
      const originalOnMessage = vtsWebSocket.onmessage;
      const messageHandler = (event) => {
        if (originalOnMessage) {
          originalOnMessage(event);
        }
      };
      vtsWebSocket.onmessage = messageHandler;
      
      try {
        for (let i = 0; i < channelData.length; i += samplesPerInterval) {
          // 音量の計算
          let sum = 0;
          for (let j = 0; j < samplesPerInterval && (i + j) < channelData.length; j++) {
            sum += Math.abs(channelData[i + j]);
          }
          const volume = sum / samplesPerInterval;
          const mouthOpenValue = Math.min(Math.max(volume * 8, 0), 1);
          
          // パラメータ値を設定
          const parameterValues = mouthParams.map(param => ({
            id: param,
            value: mouthOpenValue,
            weight: 1
          }));
          
          const request = {
            apiName: "VTubeStudioPublicAPI",
            apiVersion: "1.0",
            requestID: `lipSync-${Date.now()}`,
            messageType: "InjectParameterDataRequest",
            data: { parameterValues }
          };
          
          vtsWebSocket.send(JSON.stringify(request));
          await new Promise(resolve => setTimeout(resolve, interval));
        }
      } finally {
        vtsWebSocket.onmessage = originalOnMessage;
        console.log('リップシンク制御完了');
      }
    }
  </script>
</body>
</html>
